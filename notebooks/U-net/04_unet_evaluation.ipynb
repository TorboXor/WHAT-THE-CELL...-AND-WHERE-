{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990310a9-d4b5-4c8c-985a-96a4a4e5dad8",
   "metadata": {},
   "source": [
    "# Predictions and evaluation\n",
    "* Load model, predict and store masks\n",
    "* Compute IoU metric\n",
    "* Visualize examples (high/low IoU per class; image + ground truth mask + prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d72c4-a7b7-4ddd-9c07-da90305508c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select which models to load (user input only required here)\n",
    "Type in which model from the `saved_model` folder to load for which cell type. If the same model is used to predict the masks for each cell type, type in the same model name for all cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983c4ee-4c60-4033-81f8-a6457fc47209",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_astro  = \"shsy5y_MobileNetV2_steps_12_epochs_2+2\" # User input: specify model here\n",
    "mdl_cort   = \"shsy5y_MobileNetV2_steps_12_epochs_2+2\" # User input: specify model here\n",
    "mdl_shsy5y = \"shsy5y_MobileNetV2_steps_12_epochs_2+2\" # User input: specify model here\n",
    "\n",
    "mdl_dict = {\"astro\": mdl_astro, \"cort\": mdl_cort, \"shsy5y\": mdl_shsy5y}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b0e93-ac46-47a2-858d-525c3cca676d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff46f2-141a-47e0-8ef8-257004b8dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.transform import resize\n",
    "import image_modeling_import   # import image_modeling_import.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373af91b-c6bc-412f-a2cd-6e6a21a09cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory of the repository\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = pathlib.Path(curr_dir).parents[1]\n",
    "\n",
    "preproc_path = f\"{parent_dir}/data/data_preprocessed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de9fbe-f05d-43b6-80de-6858a0f71c60",
   "metadata": {},
   "source": [
    "## Specify folder name for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ad570-0aca-4317-8747-a2cbc66fdab0",
   "metadata": {},
   "source": [
    "## Predict, resize and store the masks based on the sliced images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f0955-dd6f-44fd-a1a0-7f1a1dae989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one example image to get original size\n",
    "df = pd.read_csv(\"CSVs/cells_train_astro.csv\", header = None)\n",
    "img = imageio.imread(df.loc[0,0])\n",
    "original_size = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68839985-81ea-4241-a417-98e64f85f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type, model_name in mdl_dict.items():\n",
    "        # Get image directories and model based on model selection above\n",
    "        TRAIN_PATH = f\"CSVs/cells_train_{cell_type}.csv\"\n",
    "        TEST_PATH  = f\"CSVs/cells_test_{cell_type}.csv\"\n",
    "        EVAL_PATH  = f\"CSVs/cells_eval_{cell_type}.csv\"\n",
    "        img_paths  = [TRAIN_PATH, EVAL_PATH, TEST_PATH]\n",
    "        \n",
    "        trained_model = tf.keras.models.load_model(f'saved_model/{model_name}')\n",
    "        \n",
    "        for path in img_paths:\n",
    "            # Load images as tensorflow dataset\n",
    "            dataset = image_modeling_import.load_dataset_seg(path, 10, training=False)\n",
    "            \n",
    "            # Load metadata to get image ID\n",
    "            df = pd.read_csv(path, header = None)\n",
    "            df[\"id\"] = df.apply(lambda x: x.iloc[0].split(\"/\")[-1].split(\".\")[0], axis = 1)\n",
    "            \n",
    "            # Predict masks and convert predictions in single channel numpy arrays that can be visualized as image\n",
    "            predictions = trained_model.predict(dataset)\n",
    "            predictions = tf.argmax(predictions, axis=-1)\n",
    "            predictions = predictions[..., tf.newaxis]\n",
    "            predictions = predictions.numpy()\n",
    "            predictions = predictions\n",
    "            \n",
    "            # Resize and store\n",
    "            for i, pred in enumerate(predictions):\n",
    "                pred_resized = resize(pred, original_size, anti_aliasing = False, preserve_range = True).astype(dtype = np.uint8)\n",
    "                imageio.imwrite(f\"{preproc_path}sliced_images/predictions/masks/{df['id'][i]}_pred.png\", pred_resized)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3332d6-33e0-41c3-98a0-d02b10fa68b4",
   "metadata": {},
   "source": [
    "## Recombine sliced predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23741d3-c029-4a92-83b1-798852c30c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we already made the per-cell-type-model predictions\n",
    "# and the train/test/eval split is identical for all-cell-types models and per-cell-type models,\n",
    "# we can use the csv files that are not additionally split per cell type here.\n",
    "TRAIN_PATH = 'CSVs/cells_train.csv'\n",
    "EVAL_PATH  = 'CSVs/cells_eval.csv'\n",
    "TEST_PATH  = 'CSVs/cells_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a0667-3b31-4490-bd55-5644b20a2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate lists that are filled with the desired output dataframe values (concatenate df after the loop below)\n",
    "img_id = list()\n",
    "data_subset = list()\n",
    "IoU = list()\n",
    "\n",
    "img_paths = {\"train\": TRAIN_PATH, \"eval\": EVAL_PATH, \"test\": TEST_PATH}\n",
    "\n",
    "\n",
    "for ds, path in img_paths.items():\n",
    "    # Load metadata to get image ID\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df[\"id\"] = df.apply(lambda x: x.iloc[0].split(\"/\")[-1].split(\".\")[0], axis = 1)\n",
    "    \n",
    "    # ID without slicing suffix\n",
    "    id_combined_list = df[\"id\"].apply(lambda x: x.split(\"_\")[0]).unique().tolist()\n",
    "    \n",
    "    for id_comb in id_combined_list:\n",
    "        \n",
    "        # Recombine the sliced masks\n",
    "        img_a = imageio.imread(f\"{preproc_path}sliced_images/predictions/masks/{id_comb}_a_pred.png\")\n",
    "        img_b = imageio.imread(f\"{preproc_path}sliced_images/predictions/masks/{id_comb}_b_pred.png\")\n",
    "        img_c = imageio.imread(f\"{preproc_path}sliced_images/predictions/masks/{id_comb}_c_pred.png\")\n",
    "        img_d = imageio.imread(f\"{preproc_path}sliced_images/predictions/masks/{id_comb}_d_pred.png\")\n",
    "        \n",
    "        img_left  = np.concatenate((img_a, img_c))\n",
    "        img_right = np.concatenate((img_b, img_d))\n",
    "        \n",
    "        mask_pred = np.concatenate((img_left, img_right), axis = 1).astype(dtype = np.uint8)\n",
    "        \n",
    "        imageio.imwrite(preproc_path + \"mask_predicted/masks/\" + id_comb + \"_pred.png\", mask_pred)\n",
    "        \n",
    "        # Compute and store intersections, unions, and IoU compared to original masks\n",
    "        # mask_true = imageio.imread(preproc_path + \"mask_groundtruth/\" + id_comb + \"_mask.png\") # use original masks\n",
    "        mask_true = imageio.imread(preproc_path + \"masks_used_for_model/\" + id_comb + \"_mask.png\") # use masks specified in 04_unet_data_pipeline\n",
    "        \n",
    "        intersection = ((mask_pred!=0) & (mask_true!=0)).astype(dtype = np.uint8)\n",
    "        union        = ((mask_pred!=0) | (mask_true!=0)).astype(dtype = np.uint8)\n",
    "        \n",
    "        imageio.imwrite(preproc_path + \"mask_predicted/intersections/\" + id_comb + \"_inter.png\", intersection)\n",
    "        imageio.imwrite(preproc_path + \"mask_predicted/unions/\" + id_comb + \"_union.png\", union)\n",
    "        \n",
    "        \n",
    "        IoU.append(np.sum(intersection)/np.sum(union))\n",
    "        \n",
    "        img_id.append(id_comb)\n",
    "        data_subset.append(ds)\n",
    "        \n",
    "\n",
    "        \n",
    "df_IoU = pd.DataFrame({\"dataset\": data_subset, \"id\": img_id, \"IoU\": IoU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a69e2a-5419-4861-9f1e-17a0f892456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IoU = pd.DataFrame({\"dataset\": data_subset, \"id\": img_id, \"IoU\": IoU})\n",
    "df_IoU.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc58d78-84da-4984-8487-e15085f4323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the cell type and store \n",
    "df = pd.read_csv(\"~/neuefische/ds-capstone-img-classification-segmentation/data/data_original/train.csv\") # Original train.csv from Kaggle\n",
    "df.drop_duplicates(subset = [\"id\"], inplace = True)\n",
    "\n",
    "df_IoU = df_IoU.merge(df[[\"id\",\"cell_type\"]], on = \"id\", how = \"left\")\n",
    "\n",
    "df_IoU.to_csv(\"IoU.csv\", index = False)\n",
    "\n",
    "df_IoU.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc510392-c7e1-41cb-9305-b498754a2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IoU.to_csv(\"IoU.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c30db-8042-4c7c-bd99-58ae7db5ca1a",
   "metadata": {},
   "source": [
    "## Copy predictions to new, model-specific folder\n",
    "...to avoid overwriting with predictions of different model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44740b0-43f2-4b91-8313-bdac46b72232",
   "metadata": {},
   "source": [
    "### Folder name based on model type, number of epochs, number of steps per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a1b7b-d912-436e-b25c-3575b152524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mdl_dict[\"astro\"]==mdl_dict[\"shsy5y\"]==mdl_dict[\"cort\"]:\n",
    "    n_steps  = int(mdl_dict[\"astro\"].split(\"_\")[3])\n",
    "\n",
    "    n_epochs = mdl_dict[\"astro\"].split(\"_\")[-1]\n",
    "    n_epochs = n_epochs.split(\"+\")\n",
    "    n_epochs = str(np.sum([int(ep) for ep in n_epochs]))\n",
    "    \n",
    "    pred_folder_name = mdl_dict[\"astro\"].split(\"_\")[1]\n",
    "    pred_folder_name = f\"{pred_folder_name}_allS{n_steps}E{n_epochs}\"\n",
    "    \n",
    "else:\n",
    "    pred_folder_name = mdl_dict[\"astro\"].split(\"_\")[1]\n",
    "    \n",
    "    for celltype, model in mdl_dict.items():\n",
    "        \n",
    "        n_steps = model.split(\"_\")[-3]\n",
    "        \n",
    "        n_epochs = model.split(\"_\")[-1]\n",
    "        n_epochs = n_epochs.split(\"+\")\n",
    "        n_epochs = str(np.sum([int(ep) for ep in n_epochs]))\n",
    "        \n",
    "        cell_name = celltype\n",
    "        cell_name = \"\".join([cell_name, 'S'])\n",
    "        cell_name = \"\".join([cell_name, n_steps])\n",
    "        cell_name = \"\".join([cell_name, 'E'])\n",
    "        cell_name = \"\".join([cell_name, n_epochs])\n",
    "        \n",
    "        pred_folder_name = \"_\".join([pred_folder_name, cell_name])\n",
    "    \n",
    "print(pred_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9fd6e-84c3-4051-9498-320a7da26660",
   "metadata": {},
   "source": [
    "### Copy predicted masks, intersections and unions in new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9793460-b748-413c-a37c-6e87cde8b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [\"intersections\", \"masks\", \"unions\"]:\n",
    "    \n",
    "    dir_source = f\"{preproc_path}mask_predicted/{folder}\"\n",
    "    dir_target = f\"{preproc_path}mask_predicted/{pred_folder_name}/{folder}\"\n",
    "\n",
    "    shutil.copytree(dir_source, dir_target, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c392a7-83aa-41c3-bdb4-5e7a092a2539",
   "metadata": {},
   "source": [
    "### Copy IoU.csv in new, model-specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886e07e-4e0a-4223-93f8-cb30f5bf7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"IoU.csv\"\n",
    "dir_target = f\"{preproc_path}mask_predicted/{pred_folder_name}\"\n",
    "\n",
    "shutil.copy(source, dir_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61e93e-7c60-4888-b6fc-453bc2b1188c",
   "metadata": {},
   "source": [
    "## Check with example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cca67-3965-493c-86c4-10b00dc0c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = df_IoU[\"id\"].sample(n=1).values[0]\n",
    "img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248317a-4e57-4605-8130-209669dc1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = \"0140b3c8f445\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1e987-626c-4f40-bc43-adab207b9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(f\"{parent_dir}/data/data_original/train/{img_id}.png\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea4f08-dad9-4ca0-920e-ed7194a923f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = imageio.imread(preproc_path + \"masks_used_for_model/{}_mask.png\".format(img_id))\n",
    "plt.imshow(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa3336-d039-4941-bff0-e11dbc3bfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = imageio.imread(f\"{preproc_path}/mask_predicted/masks/{img_id}_pred.png\")\n",
    "plt.imshow(prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f6333-026d-48dd-b197-b9b74bf4eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "isn = imageio.imread(f\"{preproc_path}/mask_predicted/intersections/{img_id}_inter.png\")\n",
    "plt.imshow(isn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8dad4-1bda-4c59-8bfc-c9c626275c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = imageio.imread(f\"{preproc_path}/mask_predicted/unions/{img_id}_union.png\")\n",
    "plt.imshow(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4fe85-d390-45e7-a06f-fc3aad27e462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
