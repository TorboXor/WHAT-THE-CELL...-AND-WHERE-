{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069f0974-cdac-4d6c-89e6-073f4f232c13",
   "metadata": {},
   "source": [
    "# U-net functions\n",
    "\n",
    "Here, we define and store all functions needed to build a U-net and to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7627f8-d91b-4489-982d-77062b9212ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any file that gets constructed by the notebook.\n",
    "!rm -f u_net_functions.py\n",
    "\n",
    "# For writing to a .py file\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "        print(\"Appended to file \", file)\n",
    "    else:\n",
    "        print('Written to file:', file)\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell.format(**globals()))        \n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a26c4-d334-4652-819e-c3eca0e41f12",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1319f-d9c9-4fff-9e4b-bf1c67b15b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to file: u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run u_net_functions.py\n",
    "\n",
    "# Import required packages\n",
    "import u_net_functions as unf\n",
    "\n",
    "# import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa502b-4df3-4293-8279-fe97d5583b45",
   "metadata": {},
   "source": [
    "## U-net architecture functions: U-net from scratch\n",
    "\n",
    "The functions for this U-net architecture are friendly borrowed from https://github.com/VidushiBhatia/U-Net-Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2f4672-481c-4d44-b1f0-790a7bca7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True):\n",
    "    \"\"\"\n",
    "    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning. \n",
    "    Dropout can be added for regularization to prevent overfitting. \n",
    "    The block returns the activation values for next layer along with a skip connection which will be used in the decoder\n",
    "    \"\"\"\n",
    "    # Add 2 Conv Layers with relu activation and HeNormal initialization using TensorFlow \n",
    "    # Proper initialization prevents from the problem of exploding and vanishing gradients \n",
    "    # 'Same' padding will pad the input to conv layer such that the output has the same height and width (hence, is not reduced in size) \n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,   # Kernel size   \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='HeNormal')(inputs)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,   # Kernel size\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='HeNormal')(conv)\n",
    "    \n",
    "    # Batch Normalization will normalize the output of the last layer based on the batch's mean and standard deviation\n",
    "    conv = BatchNormalization()(conv, training=False)\n",
    "\n",
    "    # In case of overfitting, dropout will regularize the loss and gradient computation to shrink the influence of weights on output\n",
    "    if dropout_prob > 0:     \n",
    "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
    "\n",
    "    # Pooling reduces the size of the image while keeping the number of channels same\n",
    "    # Pooling has been kept as optional as the last encoder layer does not use pooling (hence, makes the encoder block flexible to use)\n",
    "    # Below, Max pooling considers the maximum of the input slice for output computation and uses stride of 2 to traverse across input image\n",
    "    if max_pooling:\n",
    "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    \n",
    "    else:\n",
    "        next_layer = conv\n",
    "\n",
    "    # skip connection (without max pooling) will be input to the decoder layer to prevent information loss during transpose convolutions      \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c9905f-e275-4264-9140-2ce8efcd0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32):\n",
    "    \"\"\"\n",
    "    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,\n",
    "    merges the result with skip layer results from encoder block\n",
    "    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions\n",
    "    The function returns the decoded layer output\n",
    "    \"\"\"\n",
    "    # Start with a transpose convolution layer to first increase the size of the image\n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,\n",
    "                 (3,3),    # Kernel size\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(prev_layer_input)\n",
    "\n",
    "    # Merge the skip connection from previous block to prevent information loss\n",
    "    merge = concatenate([up, skip_layer_input], axis=3)\n",
    "    \n",
    "    # Add 2 Conv Layers with relu activation and HeNormal initialization for further processing\n",
    "    # The parameters for the function are similar to encoder\n",
    "    conv = Conv2D(n_filters, \n",
    "                 3,     # Kernel size\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')(merge)\n",
    "    conv = Conv2D(n_filters,\n",
    "                 3,   # Kernel size\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')(conv)\n",
    "    return conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba673b93-233d-48f6-9b08-d1545f2514c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=3):\n",
    "    \"\"\"\n",
    "    Combine both encoder and decoder blocks according to the U-Net research paper\n",
    "    Return the model as output \n",
    "    \"\"\"\n",
    "    # Input size represent the size of 1 image (the size used for pre-processing) \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder includes multiple convolutional mini blocks with different maxpooling, dropout and filter parameters\n",
    "    # Observe that the filters are increasing as we go deeper into the network which will increasse the # channels of the image \n",
    "    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True)\n",
    "    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True)\n",
    "    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True)\n",
    "    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True)\n",
    "    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
    "    \n",
    "    # Decoder includes multiple mini blocks with decreasing number of filters\n",
    "    # Observe the skip connections from the encoder are given as input to the decoder\n",
    "    # Recall the 2nd output of encoder block was skip connection, hence cblockn[1] is used\n",
    "    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8)\n",
    "    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4)\n",
    "    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2)\n",
    "    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters)\n",
    "\n",
    "    # Complete the model with 1 3x3 convolution layer (Same as the prev Conv Layers)\n",
    "    # Followed by a 1x1 Conv layer to get the image to the desired size. \n",
    "    # Observe the number of channels will be equal to number of output classes\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fcfd0-e1f2-4ba8-80f9-3f1a0daf6c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## U-Net with pretrained models in down conversion path\n",
    "Code partially based on https://www.tensorflow.org/tutorials/images/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12789f6e-6305-4e77-a7d5-f967e05ac527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def model_layers(pretrained_model):\n",
    "    if pretrained_model == 'VGG16':\n",
    "        layer_names = [\n",
    "            'block2_conv2',   # 64x64\n",
    "            'block3_conv3',   # 32x32\n",
    "            'block4_conv3',   # 16x16\n",
    "            'block5_conv3',   # 8x8\n",
    "            'block5_pool',    # 4x4\n",
    "        ]\n",
    "    elif pretrained_model == 'MobileNetV2':\n",
    "        layer_names = [\n",
    "            'block_1_expand_relu',   # 64x64\n",
    "            'block_3_expand_relu',   # 32x32\n",
    "            'block_6_expand_relu',   # 16x16\n",
    "            'block_13_expand_relu',  # 8x8\n",
    "            'block_16_project',      # 4x4\n",
    "        ]\n",
    "        \n",
    "    return layer_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a8b9e6-3666-4f56-9815-95a79b6c841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def unet_model(output_channels, pretrained_model):\n",
    "    if pretrained_model == 'VGG16':\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False,\n",
    "            input_tensor=Input(shape=(128, 128, 3)))\n",
    "        base_model_outputs = [base_model.get_layer(name).output for name in model_layers('VGG16')]\n",
    "\n",
    "    elif pretrained_model == 'MobileNetV2':\n",
    "        base_model = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "            input_tensor=Input(shape=(128, 128, 3)))\n",
    "        base_model_outputs = [base_model.get_layer(name).output for name in model_layers('MobileNetV2')]\n",
    "        \n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "    down_stack.trainable = False\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "    up_stack = [                 # dropout = 0.5\n",
    "        pix2pix.upsample(512, 3, apply_dropout=True),  # 4x4 -> 8x8\n",
    "        pix2pix.upsample(256, 3, apply_dropout=True),  # 8x8 -> 16x16\n",
    "        pix2pix.upsample(128, 3, apply_dropout=True),  # 16x16 -> 32x32\n",
    "        pix2pix.upsample(64, 3, apply_dropout=True),   # 32x32 -> 64x64\n",
    "    ]\n",
    "    \n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "          filters=output_channels, kernel_size=3, strides=2,\n",
    "          padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "    # print(base_model.summary())\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1a7d9-ddd0-4270-bcbd-766addbf0949",
   "metadata": {},
   "source": [
    "## Functions to display images, masks and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476de2af-0bca-44b8-ad5f-b9a75592c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d4963b-8eb7-4baa-b93e-d3f5b5762248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a3ce7-2da4-410f-8c88-0bc700790890",
   "metadata": {},
   "source": [
    "### Function to reinitialize u-net weights (for multiple training runs without carrying over the trained weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2310718c-6487-46b3-8f19-318dfe6b3953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to file  u_net_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run -a u_net_functions.py\n",
    "\n",
    "def reinitialize_weights(model):\n",
    "    for l in model.layers:\n",
    "        if hasattr(l,\"kernel_initializer\"):\n",
    "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
    "        if hasattr(l,\"bias_initializer\"):\n",
    "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
    "        if hasattr(l,\"recurrent_initializer\"):\n",
    "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
