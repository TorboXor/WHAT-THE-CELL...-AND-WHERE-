{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db28e3c3-a2d7-49a9-995f-0efda2ada453",
   "metadata": {},
   "source": [
    "# Data pipeline for unet\n",
    "Define tensorflow datasets that contain the mask either as one channel image or as N channels = N classes one hot coded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c78f15-7c19-46d5-8c6e-e8299f3ecfb1",
   "metadata": {},
   "source": [
    "## SELECT MASK TYPE HERE\n",
    "* 1 = original\n",
    "* 2 = astro masks replaced with clustering + Gauss filter\n",
    "* 3 = astro masks replaced with clustering + SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbaf6e-e71e-4d7b-b3e6-580779ee0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select mask type here\n",
    "mask_type = int(input(\"Select mask type: [1] = original, [2] = clustered/Gauss, [3] = clustered/SIFT, 1, 2 or 3:\"))\n",
    "\n",
    "if mask_type==1:\n",
    "    print(\"Original masks selected\")\n",
    "elif mask_type==2:\n",
    "    print(\"Original masks for cort/shsy5y and clustered/Gauss masks for astro selected\")\n",
    "elif mask_type==3:\n",
    "    print(\"Original masks for cort/shsy5y and clustered/SIFT masks for astro selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8e4ae-b46e-4ad7-9e7e-23cdcaac39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select appropriate mask folder (separate imports since main imports below are written to a .py script)\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "# Get the directory of the repository\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = pathlib.Path(curr_dir).parents[1]\n",
    "\n",
    "mask_path = f\"{parent_dir}/data/data_preprocessed/\"\n",
    "\n",
    "if mask_type==1:\n",
    "    mask_folder = mask_path +  \"sliced_images/masks/\"\n",
    "    unsliced_mask_folder = mask_path + \"mask_groundtruth/\"\n",
    "elif mask_type==2:\n",
    "    mask_folder = mask_path +  \"sliced_images/masks_cg/\"\n",
    "    unsliced_mask_folder = mask_path + \"mask_cluster/masks_cg/\"\n",
    "elif mask_type==3:\n",
    "    mask_folder = mask_path +  \"sliced_images/masks_cs/\"\n",
    "    unsliced_mask_folder = mask_path + \"mask_cluster/masks_cs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9839a7ac-76c4-4545-b26c-8a135b532e14",
   "metadata": {},
   "source": [
    "Copy the content of the selected mask folder into a new folder from which the masks are read after model training (to ensure that the correct masks are used for IoU computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dda1c-695a-4576-8192-832e374a1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliced masks\n",
    "dir_source = mask_folder\n",
    "dir_target = mask_path + \"sliced_images/masks_used_for_model/\"\n",
    "\n",
    "try: # First, delete the masks_used_for_model folders if they exist\n",
    "    shutil.rmtree(dir_target)\n",
    "except:\n",
    "    print(\"No folder deleted\")\n",
    "    \n",
    "shutil.copytree(dir_source, dir_target, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4e4d7-dcc4-496c-98f5-3f1006ad9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsliced masks\n",
    "dir_source = unsliced_mask_folder\n",
    "dir_target = mask_path + \"masks_used_for_model/\"\n",
    "\n",
    "try: # First, delete the masks_used_for_model folders if they exist\n",
    "    shutil.rmtree(dir_target)\n",
    "except:\n",
    "    print(\"No folder deleted\")\n",
    "    \n",
    "shutil.copytree(dir_source, dir_target, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1c74e-1edb-46b7-9101-84df52ea602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed seed for reproducability\n",
    "RSEED = 42\n",
    "\n",
    "# Remove any file that gets constructed by the notebook.\n",
    "!rm -f image_modeling.py\n",
    "!rm -r  CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e9714-a36a-4adb-b221-6e4dd9fd2c62",
   "metadata": {},
   "source": [
    "To enable writing of code to a separate .py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a31a65-a5ee-4a84-8f71-12455d7f5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "        print(\"Appended to file \", file)\n",
    "    else:\n",
    "        print('Written to file:', file)\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell.format(**globals()))        \n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488ce760-788a-43a8-a672-d483f147ad08",
   "metadata": {},
   "source": [
    "Import needed libraries. `%%write_and_run image_modeling.py` is the call of the register cell magic from above in 'w' mode (default). It writes the imports at the beginning of the `image_modeling.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b902dc-e855-4801-8511-dc33d86e625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run image_modeling.py\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa620f63-8bf6-4c5f-873f-2f385e5af23f",
   "metadata": {},
   "source": [
    "Print the tensorflow version and set the threshold for what messages will be logged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8fc98-e9ad-4b9d-a1cc-ce291de19288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(v=tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdddf7c-2982-4e46-acde-2de84e6adb4a",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Now we will use shell commands to look at the data, clean the paths to the images and split our data into train and evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf0092-33d8-49e8-a284-42ad50d18b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{parent_dir}/data/data_preprocessed/sliced_images/images/\"\n",
    "\n",
    "# Read the .csv containing the paths to the augmented images\n",
    "df = pd.read_csv(\"../run_once_preprocessing/cells_split_id.csv\")\n",
    "\n",
    "df[\"id_mergekey\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# Do train/test split on this df to ensure that all augmented images (e.g., the sliced crops)\n",
    "# end up either in train, test, or eval instead of being distributed across sub-datasets (i.e., avoid data leakage)\n",
    "df_for_split = df.copy()\n",
    "df_for_split.drop_duplicates(subset = \"id_mergekey\", inplace = True)\n",
    "\n",
    "\n",
    "df[\"id_mask\"] = mask_folder + df[\"id\"] + \"_mask.png\"\n",
    "df[\"id_mask_oh\"] = mask_folder + df[\"id\"] + \"_mask_oh.png\"\n",
    "\n",
    "df['id'] = data_dir + df[\"id\"] + '.png'\n",
    "\n",
    "df_for_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae8cb7-9186-49db-b51a-d9679fc5de73",
   "metadata": {},
   "source": [
    "## Train/eval/test split\n",
    "* train = training data\n",
    "* eval = validation data used during model training\n",
    "* test = test data for predictions after model training\n",
    "\n",
    "The code below first splits the test data (which should remain untouched) from the full data set. The random seed should remain fixed to ensure that we always get the same images as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d68655-9183-47f6-8b23-b136cbd981ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. We reserve 20% = ~121 (x4 due to the slicing) images of our data as test data\n",
    "train, test, y_train, y_test = train_test_split(df_for_split, \n",
    "                                                df_for_split.cell_type, \n",
    "                                                test_size=0.2, random_state=RSEED)\n",
    "\n",
    "# Inner merge of test and df to get the paths to masks and images (in df) only for the images contained in test after the split.\n",
    "test = test[[\"id_mergekey\"]].merge(df, on = \"id_mergekey\", how = \"inner\")\n",
    "test.sort_values(by = \"id\", inplace = True)\n",
    "\n",
    "# To test if we have data leakage (sum should be zero)\n",
    "# sum(test[\"id_mergekey\"].apply(lambda x: x in train[\"id_mergekey\"]).astype(int))\n",
    "\n",
    "# Store test data in a new folder\n",
    "!mkdir -p CSVs\n",
    "\n",
    "test[[\"id\",\"id_mask\"]].to_csv('CSVs/cells_test.csv', header = False, index = False) # labels = single channel masks\n",
    "test[[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_test_oh.csv', header = False, index = False) # labels = one-hot encoded masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78728d-e758-4e68-8176-79e42734fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test csv by cell type\n",
    "cell_types = df_for_split.cell_type.unique().tolist()\n",
    "for which_cell in cell_types:\n",
    "    test[test.cell_type == which_cell][[\"id\",\"id_mask\"]].to_csv('CSVs/cells_test_{}.csv'.format(which_cell), header = False, index = False)\n",
    "    test[test.cell_type == which_cell][[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_test_oh_{}.csv'.format(which_cell), header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f4a29-a101-443b-95dd-37c6a936c7d8",
   "metadata": {},
   "source": [
    "Here, we separate the eval data from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5f7b2-d1ed-4d81-98c4-ea5fb2b60347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. We keep 10% = ~48 images of the remaining train data as eval data.\n",
    "# The training set now contains ~436 images.\n",
    "train, test, y_train, y_test = train_test_split(train, \n",
    "                                                train.cell_type, \n",
    "                                                test_size=0.1, random_state=RSEED)\n",
    "\n",
    "train = train[[\"id_mergekey\"]].merge(df, on = \"id_mergekey\", how = \"inner\")\n",
    "train.sort_values(by = \"id\", inplace = True)\n",
    "\n",
    "test  = test[[\"id_mergekey\"]].merge(df, on = \"id_mergekey\", how = \"inner\")\n",
    "test.sort_values(by = \"id\", inplace = True)\n",
    "\n",
    "# Store train as train data and test as eval data\n",
    "train[[\"id\",\"id_mask\"]].to_csv('CSVs/cells_train.csv', header = False, index = False) # labels = single channel masks\n",
    "train[[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_train_oh.csv', header = False, index = False) # labels = one-hot encoded masks\n",
    "\n",
    "test[[\"id\",\"id_mask\"]].to_csv('CSVs/cells_eval.csv', header = False, index = False) # labels = single channel masks\n",
    "test[[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_eval_oh.csv', header = False, index = False) # labels = one-hot encoded masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702c96d-4de5-4443-a287-df470e726471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and eval by cell type\n",
    "for which_cell in cell_types:\n",
    "    train[train.cell_type == which_cell][[\"id\",\"id_mask\"]].to_csv('CSVs/cells_train_{}.csv'.format(which_cell), header = False, index = False)\n",
    "    train[train.cell_type == which_cell][[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_train_oh_{}.csv'.format(which_cell), header = False, index = False)\n",
    "    \n",
    "    test[test.cell_type == which_cell][[\"id\",\"id_mask\"]].to_csv('CSVs/cells_eval_{}.csv'.format(which_cell), header = False, index = False)\n",
    "    test[test.cell_type == which_cell][[\"id\",\"id_mask_oh\"]].to_csv('CSVs/cells_eval_oh_{}.csv'.format(which_cell), header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd355b74-eb0c-439f-ab10-d8984c93c0f0",
   "metadata": {},
   "source": [
    "## Define functions to process the data\n",
    "\n",
    "From now on we will use python and Tensorflow to define some variables and functions to be used in the second notebook when we train our CNN to segment images of cells.\n",
    "\n",
    "We set some parameters for the model and call the register cell magic `write_and_run` again this time with the `-a` flag. This makes sure that the content of the cell is appended to `image_modeling.py` and existing lines are not overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141691f-db6f-4a42-b07a-f5510b459187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# We set some parameters for the model\n",
    "CHANNELS = 3 #image RGB channels\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_SIZE = pd.read_csv(\"CSVs/cells_eval.csv\").shape[0]\n",
    "VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080aa70-b426-41d9-b807-e058aea8ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Define the function that decodes in the images\n",
    "def decode_image_seg(image, mask, reshape_dim):\n",
    "    # PNG is a compressed image format. So we want to \n",
    "    # convert this format to a numpy array we can compute with.\n",
    "    image = tf.image.decode_png(image, channels=CHANNELS)\n",
    "    mask = tf.image.decode_png(mask, channels=CHANNELS_MASK)\n",
    "    # 'decode_jpeg' returns a tensor of type uint8. We need for \n",
    "    # the model 32bit floats. Actually we want them to be in \n",
    "    # the [0,1] interval.\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Now we can resize to the desired size.\n",
    "    image = tf.image.resize(image, reshape_dim)\n",
    "    mask = tf.image.resize(mask, reshape_dim)\n",
    "    \n",
    "    return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b515f-5ea2-4fb6-ba9d-9e823cf83502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# The train set actually gives only the paths to the training images.\n",
    "# We want to create a dataset of training images, so we need a \n",
    "# function that can handle this for us.\n",
    "def decode_dataset_seg(data_row):\n",
    "    record_defaults = ['path', 'path_mask']\n",
    "    filename, filename_mask = tf.io.decode_csv(data_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    mask_bytes = tf.io.read_file(filename=filename_mask)\n",
    "    return image_bytes, mask_bytes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c058e-40da-4437-95e1-40cac7de05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Next we construct a function for pre-processing the images.\n",
    "def read_and_preprocess_seg(image_bytes, mask_bytes, augment_randomly=False):\n",
    "    if augment_randomly:\n",
    "        image, mask = decode_image_seg(image_bytes, mask_bytes, [HEIGHT, WIDTH])\n",
    "        \n",
    "        # # Randomly select whether to apply an augmentation independently for each augmentation type\n",
    "        if random.randint(0,1)==1:\n",
    "            image = tf.image.rot90(image)\n",
    "            mask = tf.image.rot90(mask)\n",
    "        if random.randint(0,1)==1:\n",
    "            image = tf.image.flip_left_right(image)\n",
    "            mask = tf.image.flip_left_right(mask)\n",
    "        if random.randint(0,1)==1:\n",
    "            image = tf.image.flip_up_down(image)\n",
    "            mask = tf.image.flip_up_down(mask)\n",
    "        \n",
    "        # Randomly select and apply only one of three augmentations\n",
    "        # augment_generator = random.randint(0,3)\n",
    "        # if augment_generator == 1:\n",
    "        #     image = tf.image.rot90(image)\n",
    "        #     mask = tf.image.rot90(mask)\n",
    "        # elif augment_generator == 2:\n",
    "        #     image = tf.image.flip_left_right(image)\n",
    "        #     mask = tf.image.flip_left_right(mask)\n",
    "        # elif augment_generator == 3:\n",
    "        #     image = tf.image.flip_up_down(image)\n",
    "        #     mask = tf.image.flip_up_down(mask)\n",
    "           \n",
    "    else:\n",
    "        image, mask = decode_image_seg(image_bytes, mask_bytes, [HEIGHT, WIDTH])\n",
    "        \n",
    "    return image, mask\n",
    "\n",
    "def read_and_preprocess_with_augmentation_seg(image_bytes, mask_bytes): \n",
    "    return read_and_preprocess_seg(image_bytes, mask_bytes, augment_randomly=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74df57-07cd-409a-a887-c3db66393284",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a image_modeling.py\n",
    "\n",
    "# Now we can create the dataset.\n",
    "def load_dataset_seg(file_of_filenames, batch_size, training=True):\n",
    "    # We create a TensorFlow Dataset from the list of files.\n",
    "    # This dataset does not load the data into memory, but instead\n",
    "    # pulls batches one after another.\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_of_filenames).\\\n",
    "        map(decode_dataset_seg)\n",
    "    \n",
    "    if training:\n",
    "        dataset = dataset.map(read_and_preprocess_with_augmentation_seg).\\\n",
    "            shuffle(SHUFFLE_BUFFER).\\\n",
    "            repeat(count=None) # Infinite iterations\n",
    "    else: \n",
    "        # Evaluation or testing\n",
    "        dataset = dataset.map(read_and_preprocess_seg).\\\n",
    "            repeat(count=1) # One iteration\n",
    "            \n",
    "    # The dataset will produce batches of BATCH_SIZE and will\n",
    "    # automatically prepare an optimized number of batches while the prior one is\n",
    "    # trained on.\n",
    "    return dataset.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d85c4-10ba-497e-b30d-740187dc63b3",
   "metadata": {},
   "source": [
    "## Testing the functions\n",
    "\n",
    "Show examples for one-hot encoded masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cd8ba-043d-4abc-b3ad-43c852bf307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_MASK = 3\n",
    "HEIGHT = 128 #image height\n",
    "WIDTH = 128 #image width\n",
    "train_path = 'CSVs/cells_train_oh.csv'\n",
    "\n",
    "train_data = load_dataset_seg(train_path, 1, training=True)\n",
    "# Create an iterator that runs over the training dataset.\n",
    "it = iter(train_data)\n",
    "\n",
    "# Iterate and see the pictures and labels\n",
    "img_batch, mask = next(it)\n",
    "mask = mask[0]\n",
    "image = img_batch[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(mask)\n",
    "ax[1].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfd623-c630-4f18-838a-af3378b7a0f5",
   "metadata": {},
   "source": [
    "Show examples for single-channel-encoded masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f19cb-1996-4d4f-9f98-33f29bb5924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_MASK = 1\n",
    "train_path = 'CSVs/cells_train.csv'\n",
    "\n",
    "train_data = load_dataset_seg(train_path, 1, training=True)\n",
    "# Create an iterator that runs over the training dataset.\n",
    "it = iter(train_data)\n",
    "\n",
    "# Iterate and see the pictures and labels\n",
    "img_batch, mask = next(it)\n",
    "mask = mask[0]\n",
    "image = img_batch[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(mask)\n",
    "ax[1].imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
